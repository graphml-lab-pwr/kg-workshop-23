{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae253a7-8b9e-415d-88e5-7e2726f3ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df50f6-ddfb-4c7c-8681-0528910dec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d87bc-a747-4d68-9316-4bb4e8b60d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pykeen.pipeline import pipeline\n",
    "from statistics import mean, median\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from rich import print\n",
    "import plwordnet\n",
    "import random\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.datasets import EagerDataset\n",
    "\n",
    "from utils import prepare_for_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa368bd-734a-47e6-8054-857ba0014b77",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a82cf-239e-4449-a4f9-d570a5c6f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)\n",
    "logging.getLogger(\"pykeen\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f23caa-6d2c-41e6-bddf-9fe17b11ce10",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484eb931-809c-4321-8c25-9f1dd07998c0",
   "metadata": {},
   "source": [
    "WordNet to semantyczna sieć słów składająca się z zestawów synonimów, zwanych synsetami, zorganizowanych w sposób hierarchiczny. Pomysł na słowosieć zrodził się na Uniwersytecie Princeton i od tego czasu stała się popularnym narzędziem w lingwistyce komputerowej.\n",
    "\n",
    "Podstawową jednostką w słowosieci jest synset, czyli zbiór synonimów reprezentujących jeden konkretny koncept lub znaczenie słowa. Na przykład słowa \"samochód\" i \"auto\" mogą tworzyć jeden synset, ponieważ wszystkie odnoszą się do tego samego konceptu.\n",
    "\n",
    "Relacje w słowosieci są kluczowym elementem jej struktury. Więcej o nich: http://nlp.pwr.wroc.pl/25-narzedzia-zasoby/wiedza/81-relacje-w-slowosieci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ef28a-1bf6-49b6-a5f8-b4cdfd6f4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDNET_PATH = Path(\"data/plwordnet/plwordnet_4_2.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231848a0-127e-481c-940d-1614e30c18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = plwordnet.load(str(WORDNET_PATH))\n",
    "print(wn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f477a27e-96c4-4f07-844e-9e9fff1e9929",
   "metadata": {},
   "source": [
    "## Ćwiczenie\n",
    "\n",
    "Przygotuj dane do treningu spełniając poniższe warunki:\n",
    "1. Pozostaw synsety, w których jednostki leksylane są wyłącznie rzeczownikami pos=`NOUN`.\n",
    "2. Pozostaw 150 000 losowych synsetów.\n",
    "3. Pozsotaw 50 pierwszych typów relacji (sortowanie wg. id).\n",
    "\n",
    "Podpowiedzi:\n",
    "1. Końcowo zbiór powinien mieć formę macierzy Numpy (wymiar n x 3) złożonej z stringów:\n",
    "    ```\n",
    "    [['{rozmowa.1 konwersacja.1 dialog.1 dyskurs.1}', 'hiperonimia', '{pogawędka.1 pogaduszka.1 pogwarka.1 pogaducha.1 rozmówka.1 gawędka.1 gawęda.3 gadu-gadu.1}']]\n",
    "    ```\n",
    "2. Strukturę wordnetu najszybciej zrozumieć analizaując początek tego pliku: https://github.com/maxadamski/plwordnet/blob/main/plwordnet/wordnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbc4ca-0fed-46c4-9a65-f43a167d8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pos_synsets(synsets: list, pos: str) -> list:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "filtered_synsets = filter_pos_synsets(wn.synsets, \"NOUN\")\n",
    "\n",
    "sampled_data = ...\n",
    "\n",
    "assert len(sampled_data.shape) == 2\n",
    "assert isinstance(sampled_data[0][0], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531389b7-997a-41c9-8822-59e814511e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = TriplesFactory.from_labeled_triples(sampled_data)\n",
    "training, testing = triples.split(0.95)\n",
    "dataset = EagerDataset(training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97f310-506f-461a-a2f4-5369b2645fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "g.add_edges_from([(h, t, {\"title\": r}) for h, r, t in dataset.training.triples])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70b691-b1c8-408a-a047-107f338a307c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459b71d-9721-4fdc-8810-f8db3b5aaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "_list_nodes = list(g.nodes)\n",
    "\n",
    "\n",
    "@interact\n",
    "def visualize(\n",
    "    nodes=widgets.SelectMultiple(\n",
    "        options=list(g.nodes), rows=10, value=[_list_nodes[0]]\n",
    "    ),\n",
    "    k=[0, 1, 2, 3],\n",
    "    toggle_physics=False,\n",
    "):\n",
    "    filtered = set(\n",
    "        chain(\n",
    "            *[\n",
    "                list(nx.single_source_shortest_path_length(g, n, cutoff=k))\n",
    "                for n in nodes\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    # print(filtered)\n",
    "    subgraph = nx.subgraph_view(g, filter_node=lambda x: x in filtered)\n",
    "    nt = Network(\n",
    "        \"500px\", \"500px\", directed=True, notebook=True, cdn_resources=\"in_line\"\n",
    "    )\n",
    "    nt.inherit_edge_colors(False)\n",
    "    nt.from_nx(subgraph)\n",
    "    nt.toggle_physics(toggle_physics)\n",
    "    display(nt.show(\"basic.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39acfed-f523-48ff-9bb1-4440dcde625a",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4242d-be56-4e11-89b3-1e155ed5da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for subset_name in [\"training\", \"testing\"]:\n",
    "    subset_metrics = {\"subset\": subset_name}\n",
    "    subset = dataset.__getattribute__(subset_name)\n",
    "    triples = subset.triples\n",
    "    subset_metrics[\"num_triples\"] = len(triples)\n",
    "    subset_metrics[\"num_entities\"] = len(np.unique(triples[:, [0, 2]]))\n",
    "    subset_metrics[\"num_relations\"] = len(np.unique(triples[:, 1]))\n",
    "    data.append(subset_metrics)\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff788fca-9b36-4e75-b283-3f9d0201f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "metrics[\"n_connected_components\"] = nx.number_connected_components(g.to_undirected())\n",
    "metrics[\"mean_size_of_connected_components\"] = mean(\n",
    "    len(c) for c in nx.connected_components(g.to_undirected())\n",
    ")\n",
    "metrics[\"median_size_of_connected_components\"] = median(\n",
    "    len(c) for c in nx.connected_components(g.to_undirected())\n",
    ")\n",
    "metrics[\"density\"] = nx.density(g)\n",
    "metrics[\"number_of_selfloops\"] = nx.number_of_selfloops(g)\n",
    "metrics[\"average_clustering\"] = nx.average_clustering(g)\n",
    "pd.DataFrame({\"training\": metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05759824-c591-405d-9606-d15e8200f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = sorted(g.degree(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "x, y = zip(*degree_sequence)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].set_title(\"Degree of nodes\")\n",
    "axes[0].barh(y=x, width=y)\n",
    "axes[1].set_title(\"Degree Histogram\")\n",
    "sns.histplot([d for n, d in g.degree()], ax=axes[1], log_scale=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37843205-f5cf-4a77-8f5c-87e0d65cc5b4",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266901d4-bc7c-4278-8bc8-31e799e2c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODELS = True # or load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0ec1d-0f32-42b9-a08e-ce18b8292e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location = Path(\"results/plwordnet\")\n",
    "\n",
    "if TRAIN_MODELS:\n",
    "    result = pipeline(\n",
    "        dataset=dataset,\n",
    "        model=\"TransE\",\n",
    "        model_kwargs={\"embedding_dim\": 32},\n",
    "        loss=\"nssa\",\n",
    "        loss_kwargs={\"adversarial_temperature\": 0.34, \"margin\": 9},\n",
    "        optimizer=\"Adam\",\n",
    "        optimizer_kwargs={\"lr\": 0.004},\n",
    "        negative_sampler_kwargs={\"num_negs_per_pos\": 33},\n",
    "        training_kwargs=dict(\n",
    "            num_epochs=25,\n",
    "            batch_size=512,\n",
    "            use_tqdm_batch=False,\n",
    "        ),\n",
    "        random_seed=123,\n",
    "    )\n",
    "    save_location.mkdir(exist_ok=True, parents=True)\n",
    "    result.save_to_directory(save_location)\n",
    "    print(f\"Saved: {os.listdir(save_location)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704a3fe-e988-43ff-8215-4335af746af1",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d874e8-4be3-47d6-87d1-4f5282c1cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODELS:\n",
    "    result.plot_losses()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c5792-ec32-470d-aec0-d65558a5071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODELS:\n",
    "    metrics = result.metric_results.to_df()\n",
    "    display(metrics[(metrics.Side == \"both\") & (metrics.Type == \"realistic\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd0181-717b-446e-b486-69aaa622dc0b",
   "metadata": {},
   "source": [
    "## Embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe46181-124b-45fe-b144-51c2d51af94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODELS:\n",
    "    model = result.model\n",
    "else:\n",
    "    model  = torch.load(save_location / 'trained_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8263fa-0045-49a0-a141-410b9928adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.entity_representations[0](torch.arange(dataset.num_entities))\n",
    "labels = np.array(\n",
    "    [dataset.training.entity_id_to_label[i] for i in range(dataset.num_entities)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6dcac-7b1e-4837-8938-5b65a2c6397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_embeddings_idx = random.sample(list(range(len(embeddings))), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d4e76-08d1-4c96-9d13-2b39bdc03448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_for_visualization(\n",
    "    embeddings.detach().numpy()[sampled_embeddings_idx],\n",
    "    labels[sampled_embeddings_idx],\n",
    "    Path(\"logs/plwordnet\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7ea8c-f74d-456a-ba29-69a0e0e11b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=logs/plwordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cda177-5e45-4d05-8e6a-aceb1b2d51d4",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a23564-33e3-4779-b43a-231facd2ee5d",
   "metadata": {},
   "source": [
    "Przeklej kod z poprzedniego notebooka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef817a-5995-490a-83e8-edc4928374e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
